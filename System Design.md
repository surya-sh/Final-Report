---
updated: 2025-04-06T11:18
---

System Design
=============

Overview of Architecture
------------------------

The proposed architecture consists of four deep learning models—EfficientNetV2S, EfficientNetV2M, InceptionResNetV2, and XceptionNet—each trained independently on the HAM10000 dataset. These models are then combined through an ensemble averaging mechanism. The ensemble model takes the dermatoscopic image as input, preprocesses it to match the input dimensions of the models, and feeds it into each network. The resulting predictions are averaged to generate a final output. This ensemble-based approach reduces individual model biases and improves classification robustness. The final model is then integrated into a Gradio web application for real-time use.

Functional Architecture
-----------------------

The system begins with image acquisition through the web interface. The image is preprocessed—resized, normalized, and augmented as needed—before being passed to the ensemble model. Each of the four CNN models processes the image independently, and their outputs are combined. The combined prediction is then decoded into one of the seven skin cancer classes. Finally, the result, including a detailed description of the condition, is displayed to the user. This flow ensures end-to-end automation, from user input to diagnosis delivery.

Transformer Architecture (Reference)
------------------------------------

While not directly used in this project, the Transformer architecture is briefly explored for its potential future use in skin lesion classification. Originally developed for NLP, Transformers have shown success in vision tasks through Vision Transformers (ViT). These models use self-attention mechanisms to understand global image features, making them valuable for detecting skin lesions that vary greatly in appearance. In future enhancements, this architecture may replace or augment CNN-based approaches.

UML Diagrams
------------

### Use Case Diagram ###

This diagram showcases the interaction between the user (dermatologist or patient) and the system. The main use case involves uploading an image and receiving a diagnosis. Other use cases include model training, result viewing, and feedback submission.

```mermaid
%%{init: {'theme': 'default'}}%%
%% Use Case Diagram for Skin Cancer Detection Web Application %%
%% Using CNN, with Patients, Doctors, Client Apps, Server, and Database %%
%% Actors and their interactions with system use cases %%

%% Usecase diagram starts here
graph LR

    %% Actors
    Patient((Patient))
    Doctor((Doctor))
    ClientApp@{ shape: win-pane, label: "Client Application" }
    Server@{ shape: hex, label: "Server" }
    Database[(Database)]

    %% Use Cases
    UploadImage@{ shape: subproc, label: "Upload Skin Image" }
    GetDiagnosis@{ shape: subproc, label: "Get CNN Diagnosis" }
    ViewReport@{ shape: subproc, label: "View Diagnosis Report" }
    ManagePatients@{ shape: docs, label: "Manage Patients"}
    RunCNN@{ shape: procs, label: "Run CNN Model"}
    StoreResults@{ shape: das, label: "Store Diagnosis Results" }

    %% Actor to Client Interactions
    Patient --> ClientApp
    Doctor --> ClientApp

    %% Client to Server Interactions
    ClientApp --> UploadImage
    ClientApp --> ViewReport
    ClientApp --> GetDiagnosis
    Doctor --> ManagePatients

    %% Server to Internal Components
    UploadImage --> Server
    ViewReport --> Server
    GetDiagnosis --> Server
    ManagePatients --> Server

    Server --> RunCNN
    RunCNN --> StoreResults
    StoreResults --> Database
    ViewReport --> Database
    GetDiagnosis --> Database

```

### Sequence Diagram ###

This diagram represents the chronological flow: the user uploads an image, the image is processed, predictions are generated by the ensemble model, and the result is returned. It captures the real-time, interactive nature of the system.

```mermaid
sequenceDiagram
    participant Patient
    participant Doctor
    participant ClientApp as Client Application
    participant Server
    participant DB as Database

    %% Patient uploads image for diagnosis
    Patient->>ClientApp: Upload skin image
    ClientApp->>Server: Send image data
    Server->>Server: Preprocess image
    Server->>Server: Run CNN model
    Server->>DB: Store diagnosis result
    DB-->>Server: Confirm storage
    Server->>ClientApp: Return diagnosis result
    ClientApp->>Patient: Display diagnosis

    %% Doctor logs in to view patient report
    Doctor->>ClientApp: Login and request patient reports
    ClientApp->>Server: Request reports for patient
    Server->>DB: Query diagnosis data
    DB-->>Server: Return diagnosis data
    Server->>ClientApp: Send report to doctor
    ClientApp->>Doctor: Display report
```
### Activity Diagram ###

The activity diagram outlines the complete workflow—from system initialization, image upload, and preprocessing, to prediction generation and display. It provides a visual representation of the logic and sequence of operations, ensuring a clear understanding of system functionality.

```mermaid
C4Dynamic
    title Activity Flow – Skin Cancer Detection Web Application

    %% Define actors and systems
    Person(patient, "Patient", "Uploads a skin lesion image via the client app")
    Person(doctor, "Doctor", "Reviews diagnosis and consults with the patient")
    Container(client, "Client Application", "Web/Mobile App", "Interface for patients to upload images and view results")
    Container(server, "Server", "Web Server", "Processes images using a CNN to detect skin cancer")
    ContainerDb(database, "Database", "Database", "Stores patient records, images, and diagnosis results")

    %% Define interactions between the elements
    Rel(patient, client, "Uploads image", "HTTPS")
    Rel(client, server, "Sends image data", "HTTPS/JSON")
    Rel(server, database, "Stores image & results", "JDBC/SQL")
    Rel(server, doctor, "Sends diagnosis report", "REST API")
    Rel(doctor, database, "Updates patient record", "SQL")

```
